{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymgWO1GeRXGf",
        "outputId": "226a3ec8-21f3-4320-c7b1-f69e0644bce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.8.0-py3-none-any.whl (105 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/105.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m102.4/105.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.8.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#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\n",
        "GROQ_API_KEY=\"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\""
      ],
      "metadata": {
        "id": "zv0GYHQCRg_F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=GROQ_API_KEY,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": '''You are Ben, an expert in the domain and specialist in financial and actuarial mathematics,\n",
        "                          as well as artificial intelligence. You possess the ability to understand everything,\n",
        "                          especially in evaluating credit risk stability. Your task is to describe the definitions of features in a way that is easy to understand\n",
        "                          and find the relation of data, explaining their significance and reasons.\n",
        "                          You can also guide on how to discover insights from these features.\n",
        "                          Your audience is data scientists who are confused by the complexity and detailed definitions of data.if you understand say \"Yes\"'''\n",
        "                          },\n",
        "\n",
        "        {    \"role\": \"user\",\n",
        "             \"content\" : '''This is example of your answer\n",
        "                          \"classificationofcontr_1114M\n",
        "                          Definition: Classificiation of the active contract.\n",
        "                          Explanation: This feature categorizes active contracts based on various criteria\n",
        "                          such as loan type, risk level, or contractual terms.\n",
        "                          It helps distinguish between different types of ongoing credit agreements, aiding in portfolio management\n",
        "                          and risk assessment.\n",
        "\n",
        "                          contractdate_551D\n",
        "                          Definition: Contract date of the active contract.\n",
        "                          Explanation: This feature indicates the date when the active contract was initiated or established.\n",
        "                          It provides information about the timing of the contract inception,\n",
        "                          facilitating temporal analysis and tracking contract lifecycle events.\n",
        "\n",
        "                          Now, Help me in this\n",
        "\n",
        "                          actualdpd_943P\n",
        "                          description : Days Past Due (DPD) of previous contract (actual).\n",
        "                          annuity_853A\n",
        "                          description : Monthly annuity for previous applications.\n",
        "                          cancelreason_3545846M\n",
        "                          description : Application cancellation reason.\n",
        "                          creationdate_885D\n",
        "                          description : Date when previous application was created.\n",
        "                          credacc_credlmt_575A\n",
        "                          description : Credit card credit limit provided for previous applications.\n",
        "                          credamount_590A\n",
        "                          description : Loan amount or card limit of previous applications.\n",
        "                          credtype_587L\n",
        "                          description : Credit type of previous application.\n",
        "                          district_544M\n",
        "                          description : District of the address used in the previous loan application.\n",
        "                          downpmt_134A\n",
        "                          description : Previous application downpayment amount.\n",
        "                          education_1138M\n",
        "                          description : Applicant's education level from their previous application.\n",
        "                          inittransactioncode_279L\n",
        "                          description : Type of the initial transaction made in the previous application of the client.\n",
        "                          isbidproduct_390L\n",
        "                          description : Flag for determining if the product is a cross-sell in previous applications.\n",
        "                          postype_4733339M\n",
        "                          description : Type of point of sale.\n",
        "                          profession_152M\n",
        "                          description : Profession of the client during their previous loan application.\n",
        "                          rejectreason_755M\n",
        "                          description : Reason for previous application rejection.\n",
        "                          rejectreasonclient_4145042M\n",
        "                          description : Reason for rejection of the client's previous application.\n",
        "                          status_219L\n",
        "                          description : Previous application status.''',\n",
        "        }\n",
        "    ],\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "    temperature=0.3,\n",
        "    stop = None\n",
        ")\n",
        "Ben_answer = chat_completion.choices[0].message.content\n",
        "print(Ben_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdfyEtGISG_x",
        "outputId": "cce7ddd4-775c-48f5-c6db-5b0233e4c3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, I understand. I'll provide simple and understandable definitions for each feature, along with their explanations and significance.\n",
            "\n",
            "1. actualdpd_943P\n",
            "   - Definition: Number of days past due on the previous contract.\n",
            "   - Explanation: This feature shows if the borrower has been late on their previous contract payments and by how many days. It helps assess the borrower's payment behavior and credit risk.\n",
            "\n",
            "2. annuity_853A\n",
            "   - Definition: Monthly payment for the previous loan or credit card applications.\n",
            "   - Explanation: This feature provides information about the borrower's financial obligation in their previous loan or credit card applications. It can help evaluate the borrower's repayment capacity.\n",
            "\n",
            "3. cancelreason_3545846M\n",
            "   - Definition: Reason for cancellation of the previous application.\n",
            "   - Explanation: This feature explains why the borrower's previous application was cancelled. It can offer insights into the borrower's reliability or commitment.\n",
            "\n",
            "4. creationdate_885D\n",
            "   - Definition: Date when the previous application was created.\n",
            "   - Explanation: This feature shows when the borrower submitted their previous loan application. It can help analyze the borrower's application frequency and consistency.\n",
            "\n",
            "5. credacc_credlmt_575A\n",
            "   - Definition: Credit limit provided for the previous credit card applications.\n",
            "   - Explanation: This feature indicates the credit limit offered to the borrower in their previous credit card applications. It can help assess the borrower's creditworthiness.\n",
            "\n",
            "6. credamount_590A\n",
            "   - Definition: Loan amount or credit limit for the previous applications.\n",
            "   - Explanation: This feature shows the loan amount or credit limit the borrower applied for in their previous applications. It can help understand the borrower's typical funding needs.\n",
            "\n",
            "7. credtype_587L\n",
            "   - Definition: Credit type of the previous application.\n",
            "   - Explanation: This feature indicates the type of credit product the borrower applied for in their previous application. It can help segment borrowers based on credit preferences.\n",
            "\n",
            "8. district_544M\n",
            "   - Definition: District of the borrower's address in the previous loan application.\n",
            "   - Explanation: This feature provides geographical information about the borrower's location. It can help identify regional trends or patterns.\n",
            "\n",
            "9. downpmt_134A\n",
            "   - Definition: Down payment amount for the previous application.\n",
            "   - Explanation: This feature shows the down payment the borrower made in their previous application. It can help evaluate the borrower's financial commitment.\n",
            "\n",
            "10. education_1138M\n",
            "    - Definition: Education level of the borrower from their previous application.\n",
            "    - Explanation: This feature reveals the borrower's education level. It can help assess the borrower's potential income and financial literacy.\n",
            "\n",
            "11. inittransactioncode_279L\n",
            "    - Definition: Type of the initial transaction made in the previous application.\n",
            "    - Explanation: This feature describes the type of transaction the borrower made in their previous application. It can help understand the borrower's transaction behavior.\n",
            "\n",
            "12. isbidproduct_390L\n",
            "    - Definition: Flag for determining if the product is a cross-sell in the previous applications.\n",
            "    - Explanation: This feature indicates if the borrower was offered a cross-sell product in their previous application. It can help analyze the borrower's product interest and sales strategy effectiveness.\n",
            "\n",
            "13. postype_4733339M\n",
            "    - Definition: Type of point of sale for the previous application.\n",
            "    - Explanation: This feature shows the sales channel or point of sale used in the borrower's previous application. It can help evaluate the borrower's channel preference.\n",
            "\n",
            "14. profession_152M\n",
            "    - Definition: Profession of the borrower during their previous loan application.\n",
            "    - Explanation: This feature discloses the borrower's profession. It can help assess the borrower's income stability and job security.\n",
            "\n",
            "15. rejectreason_755M\n",
            "    - Definition: Reason for rejection of the previous application.\n",
            "    - Explanation: This feature explains why the borrower's previous application was rejected. It can help identify areas for borrower improvement.\n",
            "\n",
            "16. rejectreasonclient_4145042M\n",
            "    - Definition: Reason for rejection of the borrower's previous application.\n",
            "    - Explanation: This feature provides details on the reason for the borrower's previous application rejection. It can help improve the borrower's understanding of their rejection.\n",
            "\n",
            "17. status_219L\n",
            "    - Definition: Status of the previous application.\n",
            "    - Explanation: This feature shows the final status of the borrower's previous application (e.g., approved, rejected, or pending). It can help assess the borrower's application outcome.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=GROQ_API_KEY,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": '''You are Veldona. Veldona is an expert in data science, financial and actuarial mathematics,\n",
        "            and artificial intelligence. She has a deep understanding of evaluating credit risk stability.\n",
        "            She knows how to manage datasets with missing values (NaNs or Nulls), especially when training models\n",
        "            such as Extra-Trees or other models that do not support missing data. If you understand, say \"Yes.\"'''\n",
        "            },\n",
        "        {\"role\": \"user\",\n",
        "          \"content\" :  '''this a detail or info of my data\n",
        "                          <class 'pandas.core.frame.DataFrame'>\n",
        "                          RangeIndex: 1526659 entries, 0 to 1526658\n",
        "                          Columns: 1144 entries, case_id to mean_num_group2\n",
        "                          dtypes: bool(1), category(83), float64(867), int64(5), int8(2), object(186)\n",
        "\n",
        "                          So, Can you tell me how to manages this data''',\n",
        "        }\n",
        "    ],\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "    temperature= 0.3,\n",
        "    stop = None\n",
        ")\n",
        "veldona_answer = chat_completion.choices[0].message.content\n",
        "print(veldona_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89171fad-d185-48c6-a632-acb61213ee25",
        "id": "OSINIW0YYxlo"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, I understand. Here is a general approach to manage the given dataset, which is in the form of a pandas DataFrame, with missing values:\n",
            "\n",
            "1. Check for missing values: You can use the `isnull()` method to check for missing values in the DataFrame. This will return a DataFrame with the same shape as the original, but with `True` values where there are missing values and `False` values otherwise.\n",
            "\n",
            "    Example: `missing_values = df.isnull()`\n",
            "\n",
            "2. Count missing values: You can use the `sum()` method on the DataFrame returned from step 1 to count the number of missing values in each column.\n",
            "\n",
            "    Example: `missing_values_count = missing_values.sum()`\n",
            "\n",
            "3. Decide on a strategy for handling missing values: There are several strategies for handling missing values, including:\n",
            "\n",
            "   a. Removing rows or columns with missing values: This can be done using the `dropna()` method. However, this can lead to loss of information and should be used with caution.\n",
            "\n",
            "   b. Imputing missing values: This involves replacing missing values with a value derived from the other data. For example, you could replace missing values with the mean, median, or mode of the non-missing values in the column. You can use the `fillna()` method to impute missing values.\n",
            "\n",
            "   c. Using models that support missing data: Some machine learning models, such as Extra-Trees, can handle missing data. However, it is still a good idea to check the distribution of missing values and consider imputing or removing rows or columns if necessary.\n",
            "\n",
            "4. Preprocess categorical variables: For categorical variables, you can use one-hot encoding or label encoding to convert them into numerical variables. You can use the `get_dummies()` method for one-hot encoding.\n",
            "\n",
            "5. Normalize or standardize numerical variables: You can use the `StandardScaler()` or `MinMaxScaler()` methods from the `sklearn.preprocessing` module to normalize or standardize numerical variables.\n",
            "\n",
            "6. Split the data into training and testing sets: You can use the `train_test_split()` method from the `sklearn.model_selection` module to split the data into training and testing sets.\n",
            "\n",
            "7. Train and evaluate the model: You can use the training set to train the model and the testing set to evaluate its performance. You can use the `fit()` method to train the model and the `predict()` method to make predictions.\n",
            "\n",
            "Note: The specific steps and methods used may vary depending on the problem and the data. The above steps are a general approach to managing and preprocessing the given dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=GROQ_API_KEY,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": '''You are Max. Max is an expert in data science, financial and actuarial mathematics,\n",
        "            and artificial intelligence. He has a deep understanding of evaluating credit risk stability.\n",
        "            He can generate code from command to manage datasets with missing values (NaNs or Nulls), especially when training models such as Extra-Trees\n",
        "            or other models that do not support missing data. If you understand, say \"The time to hero!!!!!\"'''\n",
        "            },\n",
        "        {  \"role\": \"user\",\n",
        "          \"content\" : ''' this a detail or info of my data\n",
        "                          <class 'pandas.core.frame.DataFrame'>\n",
        "                          RangeIndex: 1526659 entries, 0 to 1526658\n",
        "                          Columns: 1144 entries, case_id to mean_num_group2\n",
        "                          dtypes: bool(1), category(83), float64(867), int64(5), int8(2), object(186)\n",
        "\n",
        "                          So, Can you tell me how to manages this data. Generate code ''' + veldona_answer\n",
        "        }\n",
        "    ],\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "    temperature= 0.3,\n",
        "    stop = None\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "ybnlaok2hCgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87318a13-1b60-4fdf-a2ea-5dee859a169c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time to hero! Here is some code to manage the given dataset:\n",
            "\n",
            "First, let's import the necessary libraries:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.impute import SimpleImputer\n",
            "```\n",
            "\n",
            "Next, let's load the dataset into a pandas DataFrame:\n",
            "\n",
            "```python\n",
            "df = pd.read_csv('path/to/dataset.csv')\n",
            "```\n",
            "\n",
            "Now, let's check for missing values in the dataset:\n",
            "\n",
            "```python\n",
            "missing_values = df.isnull()\n",
            "missing_values_count = missing_values.sum()\n",
            "print(missing_values_count)\n",
            "```\n",
            "\n",
            "Based on the output of the above code, we can decide on a strategy for handling the missing values. For example, let's impute the missing values with the mean of the non-missing values in the column:\n",
            "\n",
            "```python\n",
            "imputer = SimpleImputer(strategy='mean')\n",
            "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
            "```\n",
            "\n",
            "Next, let's preprocess the categorical variables in the dataset using one-hot encoding:\n",
            "\n",
            "```python\n",
            "categorical_cols = df.select_dtypes(include=['category', 'object']).columns\n",
            "df = pd.get_dummies(df, columns=categorical_cols)\n",
            "```\n",
            "\n",
            "Then, let's normalize the numerical variables in the dataset:\n",
            "\n",
            "```python\n",
            "numerical_cols = df.select_dtypes(include=['float64', 'int64', 'int8']).columns\n",
            "scaler = StandardScaler()\n",
            "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
            "```\n",
            "\n",
            "Now, let's split the dataset into training and testing sets:\n",
            "\n",
            "```python\n",
            "X = df.drop('target_variable', axis=1)\n",
            "y = df['target_variable']\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "```\n",
            "\n",
            "Finally, let's train and evaluate a machine learning model on the dataset:\n",
            "\n",
            "```python\n",
            "from sklearn.ensemble import ExtraTreesClassifier\n",
            "\n",
            "model = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "y_pred = model.predict(X_test)\n",
            "```\n",
            "\n",
            "Note: The above code is just an example and may need to be modified based on the specific problem and dataset.\n"
          ]
        }
      ]
    }
  ]
}